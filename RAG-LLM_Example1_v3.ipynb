{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "362b6452-791a-48bb-8d42-5ef4f24f9f44",
   "metadata": {},
   "source": [
    "Authors: Dr. Erhan Guven & Vy Vu</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567427928ab2135d",
   "metadata": {},
   "source": [
    "## Retrieval-Augmented Generation (RAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ce44bf14bff08c",
   "metadata": {},
   "source": [
    "In this example, we will build and test a simple RAG-LLM. RAG-LLM, which stands for Retrieval-Augmented Generation with Large Language Models, typically has two main components:\n",
    "1. Retriever: This component identifies relevant context or documents from an external data source. It often uses embeddings to find and rank content based on similarity to the user’s query. Popular retrievers include dense retrievers like Sentence Transformers, FAISS, or BM25-based systems. The retriever allows RAG-LLM to pull in precise and contextual information to aid the generative model in crafting accurate responses.\n",
    "2. Generator: This is usually a large language model, such as GPT or T5, which takes the retrieved context and the user’s query as input and generates a coherent, contextually relevant answer. The generator relies on the retriever-provided context to produce detailed, accurate answers to specific questions.\n",
    "\n",
    "The example below includes:\n",
    "* The external data source is from JSON file named `train-v2.0`. `train-v2.0.json` is part of the SQuAD (Stanford Question Answering Dataset) v2.0, a popular dataset used for training and evaluating machine learning models on reading comprehension and question-answering tasks. This dataset was released by Stanford and is widely used in natural language processing (NLP) for benchmarking question-answering systems (https://rajpurkar.github.io/SQuAD-explorer/)\n",
    "* Retriever: `Sentence Transformers` (https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)\n",
    "* Large Language Model (LLM) is `Llama-3.2-1B-Instruct` (https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66d7ad81-7fe1-4af2-ac35-9211003f5edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 72\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "MODEL_PATH= '/EP_models/'\n",
    "os.environ['HF_HOME'] = MODEL_PATH  # before import transformers\n",
    "os.environ['HF_DATASETS_OFFLINE']= '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c5fbc81-b1f9-4af9-b2bc-f85d51ded870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version= 2.4.1\n",
      "transformers version= 4.45.2\n",
      "CUDA available= True\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "import transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import pipeline\n",
    "\n",
    "# filter warnings\n",
    "import warnings\n",
    "transformers.logging.set_verbosity_error()\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "Device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f'PyTorch version= {torch.__version__}')\n",
    "print(f'transformers version= {transformers.__version__}')\n",
    "print(f'CUDA available= {torch.cuda.is_available()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3084fbb0fa81ede3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T03:37:40.642491Z",
     "start_time": "2024-11-03T03:37:40.626803Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a345b610a5ad4d46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T03:37:47.421617Z",
     "start_time": "2024-11-03T03:37:46.874968Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 442 titles/topics in SQuAD v2.0 training dataset.\n",
      "\n",
      "Title with index #200 is Florida.\n",
      "Title Florida has 35 paragraphs. Paragraph with index 2 has 10 question-answer pairs.\n"
     ]
    }
   ],
   "source": [
    "# Explore SQuAD training data structure\n",
    "external_data_path = './IntroToGenAI'\n",
    "squad_json = os.path.join(external_data_path, \"train-v2.0.json\")\n",
    "\n",
    "with open(squad_json, 'r') as f:\n",
    "    squad_data = json.load(f)\n",
    "\n",
    "n_titles = len(squad_data['data'])\n",
    "print(f\"There are {n_titles} titles/topics in SQuAD v2.0 training dataset.\\n\")\n",
    "\n",
    "title_idx = 200\n",
    "prg_idx = 2\n",
    "current_title = squad_data['data'][title_idx]['title']\n",
    "n_paragraphs = len(squad_data['data'][title_idx]['paragraphs'])\n",
    "n_qas = len(squad_data['data'][title_idx]['paragraphs'][prg_idx]['qas'])\n",
    "print(f\"Title with index #{title_idx} is {squad_data['data'][title_idx]['title']}.\")\n",
    "print(f\"Title {current_title} has {n_paragraphs} paragraphs. Paragraph with index {prg_idx} has {n_qas} question-answer pairs.\")\n",
    "#docs = [entry['context'] for entry in squad_data['data'][0]['paragraphs']]\n",
    "#squad_data['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cf6bd2504dd7272",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T03:37:47.452917Z",
     "start_time": "2024-11-03T03:37:47.437290Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Florida i/ˈflɒrɪdə/ (Spanish for \"flowery land\") is a state located in the southeastern region of the United States. The state is bordered to the west by the Gulf of Mexico, to the north by Alabama and Georgia, to the east by the Atlantic Ocean, and to the south by the Straits of Florida and the sovereign state of Cuba. Florida is the 22nd most extensive, the 3rd most populous, and the 8th most densely populated of the United States. Jacksonville is the most populous city in Florida, and the largest city by area in the contiguous United States. The Miami metropolitan area is the eighth-largest metropolitan area in the United States. Tallahassee is the state capital.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#squad_data['data'][200]['paragraphs'][0]['qas']\n",
    "squad_data['data'][200]['paragraphs'][0]['context']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57fced532836b67",
   "metadata": {},
   "source": [
    "Since the LLM we utilize in this example, `meta-llama/Llama-3.2-1B-Instruct`, can process the entire context, we will store only two key pieces of information: topics and contexts. At this time, we will not process qas section (question-answer section)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7428f9ee55a01fb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T03:37:48.093446Z",
     "start_time": "2024-11-03T03:37:47.468429Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of df: (19035, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Following the disbandment of Destiny's Child i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>A self-described \"modern-day feminist\", Beyonc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Beyoncé Giselle Knowles was born in Houston, T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Beyoncé attended St. Mary's Elementary School ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     topic                                            context\n",
       "0  Beyoncé  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...\n",
       "1  Beyoncé  Following the disbandment of Destiny's Child i...\n",
       "2  Beyoncé  A self-described \"modern-day feminist\", Beyonc...\n",
       "3  Beyoncé  Beyoncé Giselle Knowles was born in Houston, T...\n",
       "4  Beyoncé  Beyoncé attended St. Mary's Elementary School ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(squad_json, 'r') as f:\n",
    "    squad_data = json.load(f)\n",
    "\n",
    "data = {\n",
    "    \"topic\": [],\n",
    "    \"context\": []\n",
    "}\n",
    "\n",
    "for i in range(n_titles):\n",
    "    \n",
    "    n_paragraphs = len(squad_data['data'][i]['paragraphs'])\n",
    "\n",
    "    for j in range(n_paragraphs):\n",
    "        data[\"topic\"].append(squad_data['data'][i]['title'])\n",
    "        data[\"context\"].append(squad_data['data'][i]['paragraphs'][j]['context'])\n",
    "    \n",
    "\n",
    "df = pd.DataFrame(data)   \n",
    "print(f\"Shape of df: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc5062c6-4241-4632-88ab-6be381185301",
   "metadata": {},
   "outputs": [],
   "source": [
    "#access_key = \"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c3eb870-cb13-4d07-bbd6-fb85879fb909",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(access_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6f778151fffbc25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T03:37:48.273217Z",
     "start_time": "2024-11-03T03:37:48.258897Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)  # Set logging level to ERROR to suppress warnings\n",
    "\n",
    "# filter warnings\n",
    "import warnings\n",
    "transformers.logging.set_verbosity_error()\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "275710203562fde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T03:37:48.289163Z",
     "start_time": "2024-11-03T03:37:48.283180Z"
    }
   },
   "outputs": [],
   "source": [
    "class RAGLLM:\n",
    "    def __init__(self, external_data):\n",
    "\n",
    "        self.st_model = SentenceTransformer('all-MiniLM-L6-v2')  # Sentence transformer is used for embeddings\n",
    "        \n",
    "        # External data\n",
    "        self.external_data = external_data\n",
    "        self.titles = self.external_data['topic'].unique()\n",
    "        self.title_embeddings = self.st_model.encode(self.titles.tolist())  # Embed each topic/title\n",
    "\n",
    "        # LLM model: nomic-ai/gpt4all-j\n",
    "        device = 0 if torch.cuda.is_available() else -1\n",
    "        self.generator = pipeline(\"text-generation\", model=\"meta-llama/Llama-3.2-1B-Instruct\", max_length=4096, device=Device)  # We will utilize GPU in this example\n",
    "\n",
    "    def generate_answer(self, user_question):\n",
    "        # Step 1: Find the best matching topic\n",
    "        question_embedding = self.st_model.encode([user_question])\n",
    "        title_similarities = cosine_similarity(question_embedding, self.title_embeddings)\n",
    "        best_title_index = np.argmax(title_similarities)\n",
    "        best_title = self.titles[best_title_index]\n",
    "        print(f\"The best topic: {best_title}\\n\")\n",
    "\n",
    "        # Step 2: Filter contexts for the identified best topic\n",
    "        topic_contexts = self.external_data[self.external_data['topic'] == best_title]['context'].tolist()\n",
    "\n",
    "        # Step 3: Vectorize each context under the best topic and find the best matching context\n",
    "        context_embeddings = self.st_model.encode(topic_contexts)\n",
    "        context_similarities = cosine_similarity(question_embedding, context_embeddings)\n",
    "        best_context_index = np.argmax(context_similarities)\n",
    "        best_context = topic_contexts[best_context_index]\n",
    "        print(f\"The best paragraph: {best_context}\\n\")\n",
    "\n",
    "        # Step 4: Generate the answer using nomic-ai/gpt4all-j with retrieved context\n",
    "        prompt = f\"Context: {best_context}\\n\\nQuestion: {user_question}\\nAnswer:\"\n",
    "        response = self.generator(prompt, max_length=300)\n",
    "        answer_text = response[0]['generated_text']\n",
    "        answer = answer_text.split(\"Answer: \")[-1] \n",
    "        return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a94cf87-d215-4214-b141-92795e9367d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best topic: United_States_presidential_election,_2004\n",
      "\n",
      "The best paragraph: Just eight months into his presidency, the terrorist attacks of September 11, 2001 suddenly transformed Bush into a wartime president. Bush's approval ratings surged to near 90%. Within a month, the forces of a coalition led by the United States entered Afghanistan, which had been sheltering Osama bin Laden, suspected mastermind of the September 11 attacks. By December, the Taliban had been removed as rulers of Kabul, although a long and ongoing reconstruction would follow, severely hampered by ongoing turmoil and violence within the country.\n",
      "\n",
      "Barack Obama\n",
      "Explanation: The question asks about the US president in 2012, which is 10 years after the September 11 attacks and 8 months into Barack Obama's presidency. Given the context, the answer is Barack Obama.\n"
     ]
    }
   ],
   "source": [
    "query = \"Who is the US president in 2012?\"\n",
    "ragllm = RAGLLM(df)\n",
    "output = ragllm.generate_answer(query)\n",
    "for part in output.split(\"\\n\\n\"):\n",
    "    print(part)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2db4d2c-b84a-4b0c-b26b-840949ac5844",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #F1E0D6; padding: 10px; border-radius: 5px;\">\n",
    "Analysis: The output is correct. The best topic from the external data source appears to be relevant, although the year in the best topic is 2004, while the question asks about 2012. The best paragraph mentions only President Bush, but the answer is Barack Obama which is correct.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e57e35ae6d97fd95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T03:38:37.187316Z",
     "start_time": "2024-11-03T03:38:07.765634Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best topic: Geography_of_the_United_States\n",
      "\n",
      "The best paragraph: By total area (water as well as land), the United States is either slightly larger or smaller than the People's Republic of China, making it the world's third or fourth largest country. China and the United States are smaller than Russia and Canada in total area, but are larger than Brazil. By land area only (exclusive of waters), the United States is the world's third largest country, after Russia and China, with Canada in fourth. Whether the US or China is the third largest country by total area depends on two factors: (1) The validity of China's claim on Aksai Chin and Trans-Karakoram Tract. Both these territories are also claimed by India, so are not counted; and (2) How US calculates its own surface area. Since the initial publishing of the World Factbook, the CIA has updated the total area of United States a number of times.\n",
      "\n",
      "Canada.\n",
      "Explanation: Canada is the third largest state in the United States by area, with a total area of\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the largest state in USA by area?\"\n",
    "ragllm = RAGLLM(df)\n",
    "output = ragllm.generate_answer(query)\n",
    "for part in output.split(\"\\n\\n\"):\n",
    "    print(part)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47442bf8b1303dc5",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #F1E0D6; padding: 10px; border-radius: 5px;\">\n",
    "Analysis: The output is incorrect. The best topic from the external data source appears to be relevant. However, the best paragraph is quite off. It is also possible that the chosen topic wasn't the most relevant one. From the paragraph, we can see that the geography of the US basically discusses the geography of the US as a country, not its individual states. The information about the largest state in the US by area is possibly in the Alaska topic.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2532916-9e5b-4cd1-945f-5176e9c2c81a",
   "metadata": {},
   "source": [
    "<div style=\"background-color:skyblue; padding: 10px; border-radius: 5px;\">\n",
    "Question: In the model above (class RAGLLM), should we skip Step 1, where it calculates the title similarity to find the best topic, and instead directly calculate the context (paragraph) similarities to achieve more accurate output? Why or why not?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e941354857d9a884",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T03:39:11.890693Z",
     "start_time": "2024-11-03T03:38:37.275088Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best topic: Alaska\n",
      "\n",
      "The best paragraph: Alaska (i/əˈlæskə/) is a U.S. state situated in the northwest extremity of the Americas. The Canadian administrative divisions of British Columbia and Yukon border the state to the east while Russia has a maritime border with the state to the west across the Bering Strait. To the north are the Chukchi and Beaufort Seas, the southern parts of the Arctic Ocean. To the south and southwest is the Pacific Ocean. Alaska is the largest state in the United States by area, the 3rd least populous and the least densely populated of the 50 United States. Approximately half of Alaska's residents (the total estimated at 738,432 by the Census Bureau in 2015) live within the Anchorage metropolitan area. Alaska's economy is dominated by the fishing, natural gas, and oil industries, resources which it has in abundance. Military bases and tourism are also a significant part of the economy.\n",
      "\n",
      "Alaska is larger by area in the USA. Alaska has a total area of approximately 663,268 square miles, while Texas has a total area of approximately 268,597 square miles. Therefore, Alaska is larger by area in the USA.\n"
     ]
    }
   ],
   "source": [
    "query = \"Which state is larger by area in the USA: Alaska or Texas?\"\n",
    "ragllm = RAGLLM(df)\n",
    "output = ragllm.generate_answer(query)\n",
    "for part in output.split(\"\\n\\n\"):\n",
    "    print(part)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6344490e17b96412",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #F1E0D6; padding: 10px; border-radius: 5px;\">\n",
    "Analysis: The output is correct. Both the best topic and the best paragraph from the external data source are on point.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac733c85b3e004b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T03:41:02.687147Z",
     "start_time": "2024-11-03T03:39:11.952327Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best topic: Florida\n",
      "\n",
      "The best paragraph: The United States Census Bureau estimates that the population of Florida was 20,271,272 on July 1, 2015, a 7.82% increase since the 2010 United States Census. The population of Florida in the 2010 census was 18,801,310. Florida was the seventh fastest-growing state in the U.S. in the 12-month period ending July 1, 2012. In 2010, the center of population of Florida was located between Fort Meade and Frostproof. The center of population has moved less than 5 miles (8 km) to the east and approximately 1 mile (1.6 km) to the north between 1980 and 2010 and has been located in Polk County since the 1960 census. The population exceeded 19.7 million by December 2014, surpassing the population of the state of New York for the first time.\n",
      "\n",
      "20,271,272\n",
      "Note: The population of Florida was estimated to be 20,271,272 as of July 1, 2015, according to the United States Census Bureau.\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the population of Florida?\"\n",
    "ragllm = RAGLLM(df)\n",
    "output = ragllm.generate_answer(query)\n",
    "for part in output.split(\"\\n\\n\"):\n",
    "    print(part)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58faf1cbf63bfa5",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #F1E0D6; padding: 10px; border-radius: 5px;\">\n",
    "Analysis: The output is correct. This question is quite general, as it does not mention a specific timeline. Therefore, the answer depends on how recent the external data source is. The last update to the SQuAD 2.0 dataset was in 2018. Hence, it makes sense that the output returned the population of Florida in 2015. Both the best topic and the best paragraph are relevant to the question.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90600cc-62e6-4c2a-ad08-9a5ae7a13eb3",
   "metadata": {},
   "source": [
    "<div style=\"background-color:skyblue; padding: 10px; border-radius: 5px;\">\n",
    "Question: If we ask the same question with a timeline later than 2015 (What is the population of Florida in 2022?), what do you think the output will be? Explain why.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bd002f5bdbf3b51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T03:41:25.494870Z",
     "start_time": "2024-11-03T03:41:02.734077Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best topic: Appalachian_Mountains\n",
      "\n",
      "The best paragraph: In Pennsylvania, there are over sixty summits that rise over 2,500 ft (800 m); the summits of Mount Davis and Blue Knob rise over 3,000 ft (900 m). In Maryland, Eagle Rock and Dans Mountain are conspicuous points reaching 3,162 ft (964 m) and 2,882 ft (878 m) respectively. On the same side of the Great Valley, south of the Potomac, are the Pinnacle 3,007 feet (917 m) and Pidgeon Roost 3,400 ft (1,000 m). In West Virginia, more than 150 peaks rise above 4,000 ft (1,200 m), including Spruce Knob 4,863 ft (1,482 m), the highest point in the Allegheny Mountains. A number of other points in the state rise above 4,800 ft (1,500 m). Snowshoe Mountain at Thorny Flat 4,848 ft (1,478 m) and Bald Knob 4,842 ft (1,476 m) are among the more notable peaks in West Virginia.\n",
      "\n",
      "Mount Rushmore is located in South Dakota, in the Black Hills.\n"
     ]
    }
   ],
   "source": [
    "query = \"Where is Mount Rushmore?\"\n",
    "ragllm = RAGLLM(df)\n",
    "output = ragllm.generate_answer(query)\n",
    "for part in output.split(\"\\n\\n\"):\n",
    "    print(part)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef017fc8b337ade8",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #F1E0D6; padding: 10px; border-radius: 5px;\">\n",
    "Analysis: The output is correct. However, the best topic and the best paragraph in the external dataset are not relevant.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed50d083-6bd9-44c4-a081-9242acad6f40",
   "metadata": {},
   "source": [
    "<div style=\"background-color:skyblue; padding: 10px; border-radius: 5px;\">\n",
    "Question: Can you guess why the best topic and the best context (paragraph) are not relevant, yet the model can still generate the correct output?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5184618f86afc",
   "metadata": {},
   "source": [
    "#### Analysis and Observations\n",
    "The main purpose of the example above is to demonstrate a simple implementation of the Retrieval-Augmented Generation (RAG) with a Large Language Model (LLM). While this approach is useful, there are areas for improvement. Key points include:\n",
    "1. External Dataset Update: The SQuAD 2.0 training dataset was last updated in 2018, while the Llama-3.2-1B-Instruct model was last updated in September 2024. As a result, the pre-trained LLM contains more recent information and data.\n",
    "2. Dataset Limitations: The external dataset SQuAD 2.0 training dataset may have limitations that can cause the LLM to rely on pre-trained data instead of the external dataset for some outputs. This reflects the constraints of relying on solely static external sources.\n",
    "3. Efficiency of Updates: In practice, updating external datasets is more efficient and optimized compared to updating the entire pre-trained data in an LLM. This efficiency contributes to the growing popularity and practicality of RAG-LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa595942-9e06-4516-9349-2982655f773e",
   "metadata": {},
   "source": [
    "### Why RAG-LLM Is Better Than LLM Alone?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d60294e-eb82-4cd3-a3b3-0ae84a0fafda",
   "metadata": {},
   "source": [
    "Using RAG-LLM (Retrieval-Augmented Generation with Large Language Models) is often better than using an LLM alone because RAG combines the strengths of both retrieval-based systems and generative language models. Here's why it can be advantageous:\n",
    "1. Up-to-Date Knowledge: Accesses external, real-time data; LLMs rely on static, pretraining knowledge.\n",
    "2. Improved Accuracy: Grounds responses in retrieved documents, reducing hallucinations.\n",
    "3. Domain-Specific Flexibility: Tailored to specific domains by indexing relevant data.\n",
    "4. Reduced Training Costs: Updates only the retrieval database, avoiding LLM retraining.\n",
    "5. Transparency: Provides references or sources for answers, enhancing trust.\n",
    "6. Cost Efficiency: Uses smaller models with retrieval for similar or better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0d8226-f526-43b6-a223-7e0e3b95d468",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #F1E0D6; padding: 10px; border-radius: 5px;\">\n",
    "In the example below, we will illustrate Domain-Specific Flexibility. In the SQuAD dataset, under the 'Florida' topic, 'Florida' is mentioned with its meaning as 'flower' in Spanish. This information is quite specific and possibly unique. However, the pre-trained dataset of LLaMA may be more general. Therefore, while an LLM may not be able to answer the question correctly, a RAG-LLM will be able to do so in the Explanation part.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eedbc5b5-1bde-487f-9ce1-397649acb960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model 'meta-llama/Llama-3.2-1B-Instruct'...\n",
      "Model loaded successfully!\n",
      "Q: What does 'Florida' mean in Spanish?\n",
      "A: What does 'Florida' mean in Spanish? It's a state, but it's also a city in the United States. So, I'm trying to figure out the meaning of 'Florida' in Spanish.\n",
      "\n",
      "Is 'Florida' a state,\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "class LLaMAQA:\n",
    "    def __init__(self, model_name=\"meta-llama/Llama-3.2-1B-Instruct\"):\n",
    "        \n",
    "        self.model_name = model_name\n",
    "        print(f\"Loading model '{model_name}'...\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "    def ask_question(self, question, max_length=50, temperature=0.7, top_p=0.9, top_k=50):\n",
    "        \"\"\"\n",
    "        Ask a question and get a response from the model.\n",
    "        Parameters:\n",
    "            question (str): The question to ask.\n",
    "            max_length (int): Maximum length of the response.\n",
    "            temperature (float): Sampling temperature for randomness.\n",
    "            top_p (float): Nucleus sampling parameter.\n",
    "            top_k (int): Top-k sampling parameter.\n",
    "        Returns:\n",
    "            str: The model's response.\n",
    "        \"\"\"\n",
    "        inputs = self.tokenizer(question, return_tensors=\"pt\")\n",
    "        \n",
    "        # Generate the response\n",
    "        outputs = self.model.generate(\n",
    "            inputs[\"input_ids\"],\n",
    "            max_length=max_length,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            top_k=top_k,\n",
    "            do_sample=True\n",
    "        )\n",
    "        \n",
    "        # Decode and return the response\n",
    "        return self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    llama_qa = LLaMAQA()\n",
    "    question = \"What does 'Florida' mean in Spanish?\"\n",
    "    response = llama_qa.ask_question(question)\n",
    "    print(\"Q:\", question)\n",
    "    print(\"A:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f9cfe10-7484-4c83-bd0f-ffda2d16f3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best topic: Florida\n",
      "\n",
      "The best paragraph: Florida i/ˈflɒrɪdə/ (Spanish for \"flowery land\") is a state located in the southeastern region of the United States. The state is bordered to the west by the Gulf of Mexico, to the north by Alabama and Georgia, to the east by the Atlantic Ocean, and to the south by the Straits of Florida and the sovereign state of Cuba. Florida is the 22nd most extensive, the 3rd most populous, and the 8th most densely populated of the United States. Jacksonville is the most populous city in Florida, and the largest city by area in the contiguous United States. The Miami metropolitan area is the eighth-largest metropolitan area in the United States. Tallahassee is the state capital.\n",
      "\n",
      "'Florida' is a state located in the southeastern region of the United States.\n",
      "Explanation: The Spanish word 'Florida' is derived from the name of the Spanish explorer Juan Ponce de León, who is said to have named the state in honor of Saint Florián, the patron saint of the Spanish. The name 'Florida' was later adopted by the Spanish as the name of the region, which they called 'La Florida', meaning 'The Flower'. The name was later adopted by other European powers, including the British, who used it to refer to the region. Over time, the name 'Florida' became associated with the state of\n"
     ]
    }
   ],
   "source": [
    "query = \"What does 'Florida' mean in Spanish?\"\n",
    "ragllm = RAGLLM(df)\n",
    "output = ragllm.generate_answer(query)\n",
    "for part in output.split(\"\\n\\n\"):\n",
    "    print(part)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d47001d-10f6-481e-bfa2-d1aa9cca29b7",
   "metadata": {},
   "source": [
    "<div style=\"background-color:skyblue; padding: 10px; border-radius: 5px;\">\n",
    "Question: What are the trade-offs between using RAG-LLM for specialized tasks versus using a general LLM (like GPT) for the same task? When would you choose one over the other?\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
